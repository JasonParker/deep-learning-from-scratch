{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e892b668-4f87-48fa-8659-9d88e2571135",
   "metadata": {},
   "source": [
    "## Chapter 3\n",
    "### Deep learning from scratch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56eccd95-bd8a-43d3-b65b-36144aea2376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "from typing import Callable, Dict, Tuple, List\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8aaaa9-5e74-4932-8fa6-a11744fe3c6f",
   "metadata": {},
   "source": [
    "### Operations\n",
    "Operations represent the constituent functions in our neural networks. The book creates classes for these, I'm going to prefer a more functional approach.\n",
    "\n",
    "Some characteristics of these operations (pp. 73-74):\n",
    "* Forward and backward passes\n",
    "* Receive an input `ndarray` and return an output `ndarray`\n",
    "* Some operations will have parameters\n",
    "* Each operation will send outputs forward on the forward pass and will receive an \"output gradient\" on the backward pass (the partial derivative of the loss with respect to every element of the operation's output\n",
    "* On the backward pass, each operation will send an \"input gradient\" backward (the partial derivative of the loss with respect to each element of the input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "723bbae8-afbe-45f1-b096-d25aee55a2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.79751774, 1.15886005, 3.15504754]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def operation(input: ndarray) -> ndarray:\n",
    "    return \"Not implemented\"\n",
    "\n",
    "def weight_multiply(input: ndarray,\n",
    "                    weights: ndarray) -> ndarray:\n",
    "    return np.dot(input, weights)\n",
    "\n",
    "def bias_add(input: ndarray,\n",
    "             bias: ndarray) -> ndarray:\n",
    "    return input + bias\n",
    "\n",
    "def init_weights(neurons: int):\n",
    "    '''\n",
    "    Initialize weights on first forward pass of model.\n",
    "    '''\n",
    "    W = np.random.randn(neurons, neurons)\n",
    "    B = np.random.randn(1, neurons)\n",
    "    return W, B\n",
    "\n",
    "def calc_input_grad(input):\n",
    "    \n",
    "    return input_grad\n",
    "\n",
    "## Initializing stuff?\n",
    "INPUT = np.array([[1,2,3]])\n",
    "NEURONS = INPUT.shape[1]\n",
    "WEIGHTS = np.random.randn(NEURONS, NEURONS)\n",
    "BIAS = np.random.randn(1, NEURONS)\n",
    "\n",
    "\n",
    "bias_add(INPUT, BIAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb058190-0aba-489a-b856-19fe77286e50",
   "metadata": {},
   "source": [
    "### Layers\n",
    "Layers are a series of linear operations followed by a nonlinear operation.\n",
    "\n",
    "Series of operations in a typical layer:\n",
    "1. Multiply by weights\n",
    "2. Add bias term\n",
    "3. Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a62ac4fb-db41-4732-9731-50e7106002e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.150547  , 0.90437885, 0.45497504]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.math import sigmoid\n",
    "\n",
    "def layer(input: ndarray,\n",
    "         activation) -> ndarray:\n",
    "    NEURONS = input.shape[1]\n",
    "    WEIGHTS, BIAS = init_weights(NEURONS)\n",
    "    output = weight_multiply(input, WEIGHTS)\n",
    "    output = bias_add(output, BIAS)\n",
    "    output = activation(output)\n",
    "    return output\n",
    "\n",
    "layer(input = INPUT, activation = sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb54ef07-3cae-4f63-9da1-14e8c3b0f8d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.07875307, -1.18399713, -0.79782866,  0.24458374,  0.95062162,\n",
       "        -1.16922789, -0.20656699,  0.76551   ,  0.04524374,  1.53495616,\n",
       "        -0.68553201,  0.22923805, -2.243146  ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn(1, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1ff71a-8687-4cb4-8894-00526a1263d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
